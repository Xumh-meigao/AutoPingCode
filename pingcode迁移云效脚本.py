import requests
import json
import os
import time
import base64
from urllib3.exceptions import InsecureRequestWarning
from PIL import Image
import re
from bs4 import BeautifulSoup


requests.packages.urllib3.disable_warnings(InsecureRequestWarning)

# -------------------------- æ ¸å¿ƒé…ç½® --------------------------
TENANT_ID = "6064398b5b9520fa3cfe8090"
PROJECT_ID = "42095753da5a500edb73d8c098"
PROJECT_SPACE_ID = "42095753da5a500edb73d8c098"
USER_ID = "69363a48f95578dee4f984b3"
ORGANIZATION_ID = "6064398b5b9520fa3cfe8090"
WORKITEM_TYPE_ID = "37da3a07df4d08aef2e3b393"
DEFAULT_STATUS_ID = "df20e9a65f57eab0bbfe946fbd"  # é»˜è®¤çŠ¶æ€ID
# SPRINT_IDS_DEFAULT = ["565109778f6ca44653bc6bd66f"]

# ä¼˜å…ˆçº§/ä¸¥é‡ç¨‹åº¦/çŠ¶æ€/å¤„ç†äººæ˜ å°„
PRIORITY_MAP = {
    "æœ€é«˜": "a2ef76837be379de92a236ea96",
    "è¾ƒé«˜": "4fc7fdc14893848bcae822d4ef",
    "ä¸€èˆ¬": "7956b23e9d26f0e97d3274fa86",
    "è¾ƒä½": "9810eccc48e35cb80852ef717e"
}
SERIOUS_LEVEL_MAP = {
    "è‡´å‘½": "4125fbce94f1404accde51af17",
    "ä¸¥é‡": "221d2b06bc3b0eef0c8ededb03",
    "ä¸€èˆ¬": "8c1eca1f6ee1882dec8789b25a",
    "å»ºè®®": "8cffbfa06b1faa2ebf3c2807bd"
}
STATUS_MAP = {
    "ä¿®å¤å®Œæˆ": "11ba1ffa50f92fee3f529c666a",
    "å†æ¬¡æ‰“å¼€": "30",
    "æŒ‚èµ·": "df20e9a65f57eab0bbfe946fbd",
    "å¤„ç†ä¸­": "100010",
    "å…³é—­": "100085",
    "æ–°æäº¤": "a0b2e1cb84ed8289494bb7fb14",
    "ä¿æŒè§‚å¯Ÿ": "11ba1ffa50f92fee3f529c666a"}

ASSIGNEE_MAP = {
    "åˆ˜ä¼Ÿç§‘": "60c1919aaa6381038e49362e",
    "æŸ¥æ™ºæ–‡": "60643979e5ccc4277855ad35",
    "è®¸é“­å®": "692ff7aea9444359a9152c2d",
    "ç‹å¼º": "60c1919a750bbcd1c05a0e12",
    "ä¿å°š": "69081fe719f260d93e5da3ff",
    "Minisform-æµ‹è¯•ç»„": "692ff7aea9444359a9152c2d",
    "æ›¹æ¬£å“²": "68999586a9444359a91de631",
    "é˜®è´¤ç‚½": "69363bedccafad1056b41876",
    "ä½•çª": "69363a48f95578dee4f984b3",
    "è¢æ—º": "695b26cb50168a3e7ea36267"
}

# æœ‰æ•ˆCookieå’ŒCSRF Token
COOKIE = "**"
APIPOST_CSRF_TOKEN = "**"
CREATE_BUG_URL = "https://devops.aliyun.com/projex/api/workitem/workitem?_input_charset=utf-8"


# -------------------------- å·¥å…·å‡½æ•° --------------------------
def get_csrf_token_from_cookie():
    try:
        return APIPOST_CSRF_TOKEN
    except Exception as e:
        try:
            xsrf_token = COOKIE.split("XSRF-TOKEN=")[1].split(";")[0].strip()
            return xsrf_token
        except IndexError:
            try:
                cr_token = COOKIE.split("cr_token=")[1].split(";")[0].strip()
                return cr_token
            except IndexError:
                print("âŒ æ— æ³•ä»Cookieæå–CSRF Token")
                return None


def build_bug_description(html_str):
    if html_str.startswith("p>"):
        html_str = "<" + html_str
    soup = BeautifulSoup(html_str, "html.parser")
    for p_tag in soup.find_all("p"):
        if not p_tag.get_text(strip=True):
            p_tag.decompose()
    html_parts = []
    jsonml_nodes = []
    current_time = int(time.time())
    for tag in soup.contents:
        if tag.name is None:
            continue
        if tag.name == "p":
            text_content = tag.get_text(strip=True)
            if not text_content:
                continue
            text_html = text_content.replace('\n', '<br>')
            html_parts.append(f'<p style="text-align:left;line-height:1.6"><span>{text_html}</span></p>')
            jsonml_nodes.append(["p", {"style": "text-align:left;line-height:1.6"},
                                 ["span", {"data-type": "text"}, ["span", {"data-type": "leaf"}, text_content]]])
        elif tag.name == "img":
            img_src = tag.get("src", "")
            img_alt = tag.get("alt", "æœªå‘½åå›¾ç‰‡")
            img_style = tag.get("style", "text-align:center;")
            img_size = tag.get("size", "0")
            if not img_src:
                continue
            align_style = "text-align:center;margin:16px 0;"
            if "text-align" in img_style:
                align_style = img_style + ";margin:16px 0;"
            img_html = f'<p style="{align_style}"><img src="{img_src}" style="width:auto;height:auto;max-width:100%" /></p>'
            html_parts.append(img_html.strip())
            jsonml_nodes.append(["p", {"style": align_style}, ["img",
                                                               {"id": f"img_{current_time}_{int(time.time() * 1000)}",
                                                                "name": img_alt, "size": img_size, "width": "auto",
                                                                "height": "auto", "rotation": 0, "src": img_src}]])
    final_html = f'<article class="4ever-article">{"".join(html_parts)}</article>'
    final_jsonml = ["root", {}] + jsonml_nodes
    return {"htmlValue": final_html.strip(), "jsonMLValue": final_jsonml}


def build_comment_content(comment_text):
    comment_html = comment_text.replace('\n', '<br>')
    rich_content = {
        "htmlValue": f'<article class="4ever-article"><p style="text-align:left;line-height:1.6">{comment_html}</p></article>',
        "jsonMLValue": ["root", {}, ["p", {"style": "text-align:left;line-height:1.6"},
                                     ["span", {"data-type": "text"}, ["span", {"data-type": "leaf"}, comment_text]]]]
    }
    return rich_content


def parse_comments(comments_list):
    """ä»…è¿‡æ»¤ç©ºè¯„è®ºï¼Œå®Œå…¨ä¿ç•™åŸå§‹å†…å®¹"""
    if not comments_list:
        return []
    return [c.strip() for c in comments_list if c and c.strip()]


# -------------------------- åˆ›å»ºBugå‡½æ•° --------------------------
def create_single_bug(bug_dict, max_retry=2):
    bug_title = bug_dict.get("title", "")
    if not bug_title:
        print(f"âŒ Bugæ ‡é¢˜ä¸ºç©º")
        return None

    # è¯»å–å­—æ®µï¼ˆå…¼å®¹å¤šå­—æ®µåï¼‰
    original_html = bug_dict.get("description", "")
    created_by = bug_dict.get("created_by", "æœªçŸ¥ç”¨æˆ·")
    created_at = bug_dict.get("created_at", 0)
    created_time = time.strftime("%Y-%m-%d %H:%M:%S", time.localtime(created_at)) if created_at else "æœªçŸ¥æ—¶é—´"

    # æ ¸å¿ƒä¿®å¤ï¼šå…¼å®¹PingCodeå¯èƒ½çš„é“¾æ¥å­—æ®µå
    bug_url = bug_dict.get("bug_url", "") or bug_dict.get("web_url", "") or bug_dict.get("workitem_url", "") or ""
    bug_url = bug_url.strip()

    # æ ¸å¿ƒä¿®å¤ï¼šå…¼å®¹PingCodeå¯èƒ½çš„çŠ¶æ€å­—æ®µå
    state_name = bug_dict.get("state_name", "") or bug_dict.get("status", "") or ""
    state_name = state_name.strip()

    # æ‹¼æ¥æè¿°ï¼ˆç¡®ä¿é“¾æ¥å¿…æ˜¾ï¼‰
    extra_html = f'''<hr style="margin:20px 0;border:none;border-top:1px solid #eee;" />
<p style="text-align:left;line-height:1.6">ç”± {created_by} åœ¨ {created_time} åˆ›å»º</p>
<p style="text-align:left;line-height:1.6">pingcodeé“¾æ¥ï¼š<a href="{bug_url}" target="_blank" style="color:#1890ff;text-decoration:underline;">{bug_url if bug_url else "æ— "}</a></p>'''
    html_content = original_html + extra_html

    bug_desc = build_bug_description(html_content)
    if not bug_desc:
        print(f"âŒ {bug_title}ï¼šæ„é€ æè¿°å¤±è´¥")
        return None

    csrf_token = get_csrf_token_from_cookie()
    if not csrf_token:
        print(f"âŒ {bug_title}ï¼šç¼ºå°‘CSRF Token")
        return None

    priority = bug_dict.get("priority", "ä¸€èˆ¬")
    priority_id = PRIORITY_MAP.get(priority, PRIORITY_MAP["ä¸€èˆ¬"])
    severity = bug_dict.get("severity", "ä¸€èˆ¬")
    severity_id = SERIOUS_LEVEL_MAP.get(severity, SERIOUS_LEVEL_MAP["ä¸€èˆ¬"])

    # çŠ¶æ€æ˜ å°„ï¼ˆä¸¥æ ¼åŒ¹é…ï¼‰
    status_id = STATUS_MAP.get(state_name, DEFAULT_STATUS_ID)
    print(f"ã€çŠ¶æ€æ˜ å°„ã€‘Bugæ ‡é¢˜ï¼š{bug_title} | state_name='{state_name}' â†’ äº‘æ•ˆçŠ¶æ€ID='{status_id}'")
    if status_id == DEFAULT_STATUS_ID and state_name != "":
        print(f"âš ï¸ æ³¨æ„ï¼šstate_name='{state_name}'æœªåœ¨STATUS_MAPä¸­é…ç½®ï¼Œå·²ä½¿ç”¨é»˜è®¤çŠ¶æ€")

    assignee = bug_dict.get("assignee", "")
    assignee_id = ASSIGNEE_MAP.get(assignee, USER_ID) if ASSIGNEE_MAP.get(assignee) != "æµ‹è¯•ç»„çš„äº‘æ•ˆID" else USER_ID

    bug_data = {
        "subject": bug_title,
        "description": json.dumps(bug_desc, ensure_ascii=False),
        "descriptionFormat": "RICHTEXT",
        "categoryIdentifier": "Bug",
        "workitemTypeIdentifier": WORKITEM_TYPE_ID,
        "workitemType": WORKITEM_TYPE_ID,
        "category": "Bug",
        "spaceIdentifier": PROJECT_SPACE_ID,
        "space": PROJECT_SPACE_ID,
        "spaceType": "Project",
        "organizationIdentifier": ORGANIZATION_ID,
        "tenantId": TENANT_ID,
        "projectId": PROJECT_ID,
        "statusIdentifier": status_id,
        "logicalStatus": "NORMAL",
        "assignedTo": assignee_id,
        "creator": USER_ID,
        "modifier": USER_ID,
        # "sprint": SPRINT_IDS_DEFAULT,
        "fieldValueList": [{"fieldIdentifier": "priority", "value": priority_id},
                           {"fieldIdentifier": "seriousLevel", "value": severity_id}],
        "identifierPath": None,
        "parentIdentifier": None,
        "directory": None,
        "finishTime": None,
        "cloneFrom": None,
        "createWorkitemRelationInfo": {},
        "serialNumber": None,
        "gmtCreate": None,
        "gmtModified": None,
        "csrfToken": csrf_token
    }

    headers = {
        "Cookie": COOKIE,
        "Content-Type": "application/json; charset=utf-8",
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) Chrome/120.0.0.0 Safari/537.36",
        "Referer": "https://devops.aliyun.com/",
        "X-CSRF-Token": csrf_token,
        "last-workspace": "6064398b5b9520fa3cfe8090",
        "priority": "u=1, i",
        "web-last-workspace": "6064398b5b9520fa3cfe8090",
        "x-requested-with": "XMLHttpRequest"
    }

    # è¶…æ—¶é‡è¯•
    for retry in range(max_retry + 1):
        try:
            response = requests.post(CREATE_BUG_URL, headers=headers, data=json.dumps(bug_data, ensure_ascii=False),
                                     timeout=30, verify=False)
            response.encoding = "utf-8"
            result = response.json()

            if response.status_code == 200 and result.get("code") == 200:
                bug_identifier = result["result"].get("identifier", "æœªçŸ¥")
                bug_internal_id = result["result"].get("id", "æœªçŸ¥")
                print(f"ğŸ‰ {bug_title} åˆ›å»ºæˆåŠŸ | ä¸šåŠ¡æ ‡è¯†ï¼š{bug_identifier}ï¼ˆå†…éƒ¨IDï¼š{bug_internal_id}ï¼‰")
                return bug_identifier
            else:
                error_msg = result.get("errorMsg", "æœªçŸ¥é”™è¯¯")
                if retry < max_retry:
                    print(f"âš ï¸ {bug_title} åˆ›å»ºå¤±è´¥ï¼ˆç¬¬{retry + 1}æ¬¡é‡è¯•ï¼‰ï¼š{error_msg}ï¼Œ5ç§’åé‡è¯•...")
                    time.sleep(5)
                else:
                    print(f"âŒ {bug_title} åˆ›å»ºå¤±è´¥ï¼ˆå·²é‡è¯•{max_retry + 1}æ¬¡ï¼‰ï¼š{error_msg}")
                    return None
        except Exception as e:
            error_info = str(e)
            if retry < max_retry:
                print(f"âš ï¸ {bug_title} åˆ›å»ºå¼‚å¸¸ï¼ˆç¬¬{retry + 1}æ¬¡é‡è¯•ï¼‰ï¼š{error_info}ï¼Œ5ç§’åé‡è¯•...")
                time.sleep(5)
            else:
                print(f"âŒ {bug_title} åˆ›å»ºå¼‚å¸¸ï¼ˆå·²é‡è¯•{max_retry + 1}æ¬¡ï¼‰ï¼š{error_info}")
                return None


def create_single_comment(bug_identifier, comment_text="", comment_user_id=USER_ID, max_retry=3, retry_delay=3):
    if not bug_identifier or not comment_text:
        print(f"âŒ è·³è¿‡æ·»åŠ è¯„è®ºï¼ˆID/å†…å®¹ä¸ºç©ºï¼‰")
        return False
    comment_content = build_comment_content(comment_text)
    csrf_token = get_csrf_token_from_cookie()
    if not csrf_token:
        print(f"âŒ ç¼ºå°‘CSRF Token")
        return False
    COMMENT_URL = f"https://devops.aliyun.com/projex/api/workitem/workitem/{bug_identifier}/comment?_input_charset=utf-8"
    comment_data = {
        "content": json.dumps(comment_content, ensure_ascii=False),
        "contentFormat": "RICHTEXT",
        "csrfToken": csrf_token,
        "parentId": None,
        "spaceIdentifier": PROJECT_SPACE_ID,
        "projectId": PROJECT_ID,
        "tenantId": TENANT_ID,
        "creator": comment_user_id,
        "modifier": comment_user_id
    }
    headers = {
        "Cookie": COOKIE,
        "Content-Type": "application/json; charset=utf-8",
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) Chrome/120.0.0.0 Safari/537.36",
        "Referer": f"https://devops.aliyun.com/workitem/{bug_identifier}",
        "X-CSRF-Token": csrf_token,
        "last-workspace": "6064398b5b9520fa3cfe8090",
        "priority": "u=1, i",
        "web-last-workspace": "6064398b5b9520fa3cfe8090",
        "x-requested-with": "XMLHttpRequest"
    }
    for retry in range(max_retry):
        try:
            response = requests.post(COMMENT_URL, headers=headers, data=json.dumps(comment_data, ensure_ascii=False),
                                     timeout=15, verify=False)
            result = response.json()
            if response.status_code == 200 and result.get("code") == 200:
                print(f"âœ… Bug[{bug_identifier}] è¯„è®ºæ·»åŠ æˆåŠŸï¼ˆè¯„è®ºè€…ï¼š{comment_user_id}ï¼‰")
                return True
            else:
                error_msg = result.get("errorMsg", f"çŠ¶æ€ç ï¼š{response.status_code}")
                if retry < max_retry - 1:
                    print(f"âš ï¸ Bug[{bug_identifier}] è¯„è®ºå¤±è´¥ï¼ˆç¬¬{retry + 1}æ¬¡ï¼‰ï¼Œ{retry_delay}ç§’åé‡è¯•...")
                    time.sleep(retry_delay)
                else:
                    print(f"âŒ Bug[{bug_identifier}] è¯„è®ºå¤±è´¥ï¼ˆé‡è¯•{max_retry}æ¬¡ï¼‰ï¼š{error_msg}")
                    return False
        except Exception as e:
            if retry < max_retry - 1:
                print(f"âš ï¸ Bug[{bug_identifier}] è¯„è®ºå¼‚å¸¸ï¼ˆç¬¬{retry + 1}æ¬¡ï¼‰ï¼Œ{retry_delay}ç§’åé‡è¯•...")
                time.sleep(retry_delay)
            else:
                print(f"âŒ Bug[{bug_identifier}] è¯„è®ºå¼‚å¸¸ï¼š{str(e)}")
                return False


# -------------------------- æ‰¹é‡åˆ›å»ºå‡½æ•° --------------------------
def batch_create_bugs(bugs_list, retry_tag="é¦–æ¬¡"):
    success_count = 0
    fail_list = []
    total_count = len(bugs_list)
    print(f"\nğŸš€ {retry_tag}æ‰¹é‡åˆ›å»ºBugï¼ˆå…±{total_count}ä¸ªï¼‰")
    print("-" * 80)

    for idx, bug_dict in enumerate(bugs_list, 1):
        bug_title = bug_dict.get("title", f"æœªå‘½åBug_{idx}")
        print(f"\n[{idx}/{total_count}] å¤„ç†ï¼š{bug_title}")

        bug_identifier = create_single_bug(bug_dict)
        if not bug_identifier:
            print(f"[{idx}/{total_count}] âŒ è·³è¿‡")
            fail_list.append(bug_dict)
            continue

        success_count += 1
        print(f"[{idx}/{total_count}] â³ ç­‰å¾…5ç§’ï¼ˆåŒæ­¥äº‘æ•ˆæ•°æ®ï¼‰...")
        time.sleep(5)

        comments_list = bug_dict.get("comments", [])
        parsed_comments = parse_comments(comments_list)
        if parsed_comments:
            print(f"[{idx}/{total_count}] ğŸ“ å¼€å§‹æ·»åŠ {len(parsed_comments)}æ¡è¯„è®º...")
            for comment_idx, comment_content in enumerate(parsed_comments, 1):
                # æ‰“å°åŸå§‹å®Œæ•´å†…å®¹ï¼ˆç¡®è®¤æ²¡è¢«ä¿®æ”¹ï¼‰
                print(f"[{idx}/{total_count}] è¯„è®º{comment_idx} åŸå§‹å†…å®¹ï¼š{comment_content}")
                # ç›´æ¥ä¼ å…¥åŸå§‹å†…å®¹ï¼Œè¯„è®ºäººIDç”¨é»˜è®¤ï¼ˆæˆ–ä½ æƒ³åŒ¹é…çš„è¯ä¹Ÿå¯ä»¥ï¼Œä½†å†…å®¹ç»å¯¹ä¸ä¿®æ”¹ï¼‰
                create_single_comment(bug_identifier, comment_content, USER_ID)
                time.sleep(1)
        else:
            print(f"[{idx}/{total_count}] ğŸ“ æ— è¯„è®º")

    print("-" * 80)
    print(f"\nğŸ {retry_tag}å®Œæˆï¼æˆåŠŸ{success_count}/{total_count}")

    if fail_list:
        print(f"\nâŒ {retry_tag}å¤±è´¥çš„Bugåˆ—è¡¨ï¼ˆå…±{len(fail_list)}ä¸ªï¼‰ï¼š")
        for i, fail_bug in enumerate(fail_list, 1):
            print(f"  {i}. {fail_bug.get('title', 'æœªå‘½åBug')} | PingCodeé“¾æ¥ï¼š{fail_bug.get('bug_url', 'æ— ')}")

    return success_count, fail_list


# -------------------------- æ‰§è¡Œå…¥å£ --------------------------
if __name__ == "__main__":
    if PROJECT_ID == "æ›¿æ¢ä¸ºä½ çš„äº‘æ•ˆé¡¹ç›®ID" or not COOKIE:
        print("âŒ è¯·å¡«å†™PROJECT_IDå’ŒCookie")
        exit()

    # # ç¬¬ä¸€æ­¥ï¼šå…ˆæ‰“å°PingCodeåŸå§‹æ•°æ®ï¼ˆæ‰¾åˆ°æ­£ç¡®å­—æ®µåï¼‰
    # print("ğŸ” ç¬¬ä¸€æ­¥ï¼šè·å–PingCodeåŸå§‹æ•°æ®ï¼Œå®šä½æ­£ç¡®å­—æ®µå...")
    # # è¯·å…ˆæ›¿æ¢debug_pingcode_raw_dataå‡½æ•°ä¸­çš„PINGCODE_TOKENï¼Œå†å–æ¶ˆæ³¨é‡Šè¿è¡Œ
    # # debug_pingcode_raw_data()

    # ç¬¬äºŒæ­¥ï¼šä»PingCodeè·å–Bugæ•°æ®ï¼ˆæ›¿æ¢åŸPingCodeClienté€»è¾‘ï¼Œå…¼å®¹å¤šå­—æ®µï¼‰
    print("\nğŸ” ç¬¬äºŒæ­¥ï¼šä»PingCodeè·å–Bugæ•°æ®...")
    try:
        from utils.ping_code_utils import PingCodeClient

        pcc = PingCodeClient()
        search_data = {
            "addon_setting_id": "6847a64c4c9434fbbce54bcf",
            "criteria": {
                "sort_by": "updated_at",
                "sort_direction": -1,
                "conditions": [
                    {"operation": 6, "property_key": "iteration", "value": ["6959e353c7330c2b08ab9761"], "logic": 1}
                ],
            },
            "columns": [
                "identifier", "title", "description",
                "state", "status",  # çŠ¶æ€ç›¸å…³å­—æ®µ
                "url", "web_url", "workitem_url",  # é“¾æ¥ç›¸å…³å­—æ®µ
                "priority", "severity", "assignee", "created_by", "created_at", "comments"
            ],
            "is_brief": 1,
            "pi": 0,
            "ps": 1000,
        }
        bugs = pcc.get_format_bug_info(search_data)
        print(f"âœ… æˆåŠŸè·å–{len(bugs)}ä¸ªBugæ•°æ®")

        # å­—æ®µæ˜ å°„ï¼ˆå…¼å®¹å¤šå­—æ®µåï¼‰
        # å­—æ®µæ˜ å°„ï¼ˆç›´æ¥è¯»å–è¿”å›æ•°æ®ä¸­çš„state_nameå’Œbug_urlï¼‰
        mapped_bugs = []
        for bug in bugs:
            # ç›´æ¥è¯»å–è¿”å›æ•°æ®ä¸­å·²æœ‰çš„state_nameå’Œbug_urlï¼ˆæ— éœ€å…¼å®¹å…¶ä»–å­—æ®µï¼‰
            raw_state = bug.get("state_name", "").strip()
            raw_url = bug.get("bug_url", "").strip()

            # è°ƒè¯•æ—¥å¿—ï¼šç¡®è®¤æ‹¿åˆ°çš„çŠ¶æ€å’Œé“¾æ¥
            print(f"ã€è°ƒè¯•ã€‘Bugæ ‡é¢˜ï¼š{bug.get('title')} | PingCodeçŠ¶æ€ï¼š'{raw_state}' | PingCodeé“¾æ¥ï¼š'{raw_url}'")

            mapped_bug = {
                "identifier": bug.get("identifier", ""),
                "title": bug.get("title", ""),
                "description": bug.get("description", ""),
                "state_name": raw_state,
                "priority": bug.get("priority", "ä¸€èˆ¬"),
                "severity": bug.get("severity", "ä¸€èˆ¬"),
                "assignee": bug.get("assignee", ""),
                "created_by": bug.get("created_by", "æœªçŸ¥ç”¨æˆ·"),
                "created_at": bug.get("created_at", 0),
                "bug_url": raw_url,
                "comments": bug.get("comments", [])
            }
            mapped_bugs.append(mapped_bug)

        # æ‰¹é‡åˆ›å»º
        first_success, fail_list = batch_create_bugs(mapped_bugs, retry_tag="é¦–æ¬¡")

        # é‡è¯•å¤±è´¥çš„Bug
        if fail_list:
            print(f"\nğŸ”„ å¼€å§‹é‡è¯•å¤±è´¥çš„Bugï¼ˆå…±{len(fail_list)}ä¸ªï¼‰...")
            time.sleep(10)
            retry_success, final_fail_list = batch_create_bugs(fail_list, retry_tag="é‡è¯•")

            total_success = first_success + retry_success
            total_count = len(mapped_bugs)
            print(f"\nğŸ“Š æœ€ç»ˆç»“æœï¼š")
            print(f"   æ€»æ•°é‡ï¼š{total_count}")
            print(f"   é¦–æ¬¡æˆåŠŸï¼š{first_success}")
            print(f"   é‡è¯•æˆåŠŸï¼š{retry_success}")
            print(f"   æœ€ç»ˆæˆåŠŸï¼š{total_success}")
            print(f"   æœ€ç»ˆå¤±è´¥ï¼š{len(final_fail_list)}")

            if final_fail_list:
                print(f"\nâŒ æœ€ç»ˆåŒæ­¥å¤±è´¥çš„Bugåˆ—è¡¨ï¼š")
                for i, fail_bug in enumerate(final_fail_list, 1):
                    print(f"  {i}. æ ‡é¢˜ï¼š{fail_bug.get('title', 'æœªå‘½åBug')}")
                    print(f"     PingCodeé“¾æ¥ï¼š{fail_bug.get('bug_url', 'æ— ')}")
                    print(f"     çŠ¶æ€ï¼š{fail_bug.get('state_name', 'æœªçŸ¥')}")
        else:
            print("\nğŸ‰ æ‰€æœ‰Bugéƒ½åŒæ­¥æˆåŠŸï¼Œæ— éœ€é‡è¯•ï¼")
    except ImportError:
        print("âŒ ç¼ºå°‘PingCodeClientæ¨¡å—ï¼Œè¯·ç¡®ä¿utils/ping_code_utils.pyå­˜åœ¨ä¸”å¯å¯¼å…¥")
    except Exception as e:
        print(f"âŒ æ‰§è¡Œå¼‚å¸¸ï¼š{str(e)}")
